{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Owlready2 Crash Notebook\n",
    "Owlready2 is a Python package to construct and manipulate ontology under Python syntax, while Protege is a Java software to construct and manipulate ontologies with various plugins.\n",
    "\n",
    "This is a notebook to manipulate owl files pre-constructed in Protege, and to utilize some APIs from Owlready2 for information retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting graphviz\n",
      "  Using cached graphviz-0.16-py2.py3-none-any.whl (19 kB)\n",
      "Installing collected packages: graphviz\n",
      "Successfully installed graphviz-0.16\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: optimized Cython parser module 'owlready2_optimized' is not available, defaulting to slower Python implementation\n"
     ]
    }
   ],
   "source": [
    "# All necessary imports\n",
    "import os\n",
    "import difflib\n",
    "import graphviz\n",
    "import owlready2 as owl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load a local *.owl file\n",
    "Owlready2 natively supports RDF/XML format ontology file. \n",
    "\n",
    "Refer to \"https://pythonhosted.org/Owlready2/onto.html\" for more details in ontology manipulation with Owlready2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded owl file at: file:///home/spc93/tmp/object_onto.owl\n"
     ]
    }
   ],
   "source": [
    "# Here, we load a local ontology file, created earlier in Protege.\n",
    "# A prefix of \"file://\" is needed.\n",
    "#onto_path = 'file://' + os.path.abspath('object_onto.owl')\n",
    "onto_path = 'file:///home/spc93/tmp/object_onto.owl'\n",
    "onto = owl.get_ontology(onto_path).load()\n",
    "print('Loaded owl file at:', onto_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Invoke a reasoner\n",
    "Reasoners are useful when checking the consistency of an ontology or deducing logical facts. Owlready2 includes a modified version of the HermiT reasoner.\n",
    "\n",
    "Refer to \"https://pythonhosted.org/Owlready2/reasoning.html\" for more details in reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Running HermiT...\n",
      "    java -Xmx2000M -cp /home/spc93/.local/lib/python3.8/site-packages/owlready2/hermit:/home/spc93/.local/lib/python3.8/site-packages/owlready2/hermit/HermiT.jar org.semanticweb.HermiT.cli.CommandLine -c -O -D -I file:////tmp/tmppvn4a23k\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'java'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2113243201ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Invoke reasoner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# NOTE: New facts will be appended into the current onto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mowl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_reasoner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/owlready2/reasoning.py\u001b[0m in \u001b[0;36msync_reasoner_hermit\u001b[0;34m(x, infer_property_values, debug, keep_tmp_file)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTDOUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_subprocess_kargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mb\"Inconsistent ontology\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dls_sw/apps/python/anaconda/4.6.14/64/envs/python3.8/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'universal_newlines'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[0m\u001b[1;32m    412\u001b[0m                **kwargs).stdout\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dls_sw/apps/python/anaconda/4.6.14/64/envs/python3.8/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stderr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dls_sw/apps/python/anaconda/4.6.14/64/envs/python3.8/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    852\u001b[0m                             encoding=encoding, errors=errors)\n\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[1;32m    855\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m                                 \u001b[0mstartupinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreationflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dls_sw/apps/python/anaconda/4.6.14/64/envs/python3.8/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1700\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0merrno_num\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m                         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1702\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1703\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'java'"
     ]
    }
   ],
   "source": [
    "# Invoke reasoner\n",
    "# NOTE: New facts will be appended into the current onto\n",
    "owl.sync_reasoner()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Some basic APIs exploration\n",
    "Some APIs that are useful to retrieve information in classes, object properties, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://pythonhosted.org/Owlready/class.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Manipulation over Classes\n",
    "# --------------------\n",
    "# Retrieve all classes inside onto\n",
    "classes = list(onto.classes())\n",
    "print('All classes\\n'+'-'*20)\n",
    "for x in classes: \n",
    "    print(x)\n",
    "print()\n",
    "    \n",
    "# Get a random class in collection\n",
    "# Access dict to retrieve more info\n",
    "cls = classes[-1]\n",
    "print(cls)\n",
    "print(cls.__dict__)\n",
    "print()\n",
    "\n",
    "# Some useful APIs here\n",
    "print('name(string):', cls.name)\n",
    "print('module_type:', cls.__module__)\n",
    "print('equivalent_to:', cls.equivalent_to)\n",
    "print('is_a:', cls.is_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve all object properties\n",
    "properties = list(onto.object_properties())\n",
    "print('\\nAll object properties\\n'+'-'*20)\n",
    "for x in properties: \n",
    "    print(x)\n",
    "print()\n",
    "    \n",
    "rel = properties[-1]\n",
    "print(rel)\n",
    "print(rel.__dict__)\n",
    "print()\n",
    "\n",
    "# Some useful APIs here\n",
    "print('name(string):', rel.name)\n",
    "print('module_type:', rel.__module__)\n",
    "print('is_a:', rel.is_a)\n",
    "print()\n",
    "\n",
    "\"\"\"\n",
    "The .class_property_type attribute of Properties allows to indicate how to handle class properties:\n",
    "    “some”: handle class properties as existential restrictions (i.e. SOME restrictions and VALUES restrictions).\n",
    "    “only”: handle class properties as universal restrictions (i.e. ONLY restrictions).\n",
    "    “relation”: handle class properties as relations (i.e. simple RDF triple, as in Linked Data).\n",
    "\"\"\"\n",
    "print('class_property_some:', rel._class_property_some)\n",
    "print('class_property_only:', rel._class_property_only)\n",
    "print('class_property_relation:', rel._class_property_relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve all disjoint sets\n",
    "disjoints = list(onto.disjoints())\n",
    "print('\\nAll disjoints\\n'+'-'*20)\n",
    "for x in disjoints: \n",
    "    # NOTE: Retreive all disjoint individual entity objects, stored in the dict\n",
    "    print(x)\n",
    "    print(x.__dict__)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Higher-level API exploration\n",
    "Some helper functions to retrieve useful info given an entity to search for. This is a mimic of ontograf plugin feature from Protege."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default type2str from owlready2\n",
    "type2str_restriction = owl.class_construct._restriction_type_2_label\n",
    "\n",
    "def _process_entity(entity, job_name, orig_entity, graph):\n",
    "    \"\"\"Helper: Append entity for the specified job.\n",
    "    \"\"\"\n",
    "    edge = (orig_entity, job_name, entity)\n",
    "    if edge not in graph:\n",
    "        graph.append(edge)\n",
    "    return graph\n",
    "\n",
    "def _process_restriction(restriction, entity, graph):\n",
    "    \"\"\"Helper: Append restriction.\n",
    "    \"\"\"\n",
    "    assert restriction.__module__ == 'owlready2.class_construct'\n",
    "    \n",
    "    # Grab object_property --type--> value\n",
    "    object_property, value = restriction.property, restriction.value\n",
    "    restriction_type = type2str_restriction[restriction.type]\n",
    "    \n",
    "    # Separate logical or for 'only'\n",
    "    if restriction_type == 'only':\n",
    "        for or_value in value.Classes:\n",
    "            edge = (entity, '{},{}'.format(object_property.name, restriction_type), or_value)\n",
    "            if edge not in graph:\n",
    "                graph.append(edge)\n",
    "            \n",
    "    # No more processing for 'some'\n",
    "    else:\n",
    "        edge = (entity, '{},{}'.format(object_property.name, restriction_type), value)\n",
    "        if edge not in graph:\n",
    "            graph.append(edge)\n",
    "        \n",
    "    return graph\n",
    "\n",
    "def _process_subclasses(entity, graph):\n",
    "    \"\"\"Helper: Append subclasses.\n",
    "    \"\"\"\n",
    "    # Safely grab all subclasses\n",
    "    try:\n",
    "        subclses = list(entity.subclasses())\n",
    "    except:\n",
    "        subclses = []\n",
    "\n",
    "    for subcls in subclses:\n",
    "        if (entity, 'has_subclass', subcls) not in graph:\n",
    "            graph.append((entity, 'has_subclass', subcls))\n",
    "        if (subcls, 'subclass_of', entity) not in graph:\n",
    "            graph.append((subcls, 'subclass_of', entity))\n",
    "\n",
    "    return graph\n",
    "\n",
    "def _populate_subclass_rel(graph):\n",
    "    \"\"\"Helper: Ensure 'subclass_of' and 'has_subclass' always appear in pairs.\n",
    "    \"\"\"\n",
    "    for edge in graph:\n",
    "        if edge[1] == 'subclass_of' and (edge[2], 'has_subclass', edge[0]) not in graph:\n",
    "            graph.append((edge[2], 'has_subclass', edge[0]))\n",
    "        elif edge[1] == 'has_subclass' and (edge[2], 'subclass_of', edge[0]) not in graph:\n",
    "            graph.append((edge[2], 'subclass_of', edge[0]))\n",
    "    return graph\n",
    "\n",
    "def _process_instances(entity, graph):\n",
    "    \"\"\"Helper: Append individuals.\n",
    "    \"\"\"\n",
    "    # Safely grab all individuals\n",
    "    try:\n",
    "        instances = entity.instances()\n",
    "    except:\n",
    "        instances = []\n",
    "\n",
    "    for instance in instances:\n",
    "        if instance.is_a[0] == entity:\n",
    "            if (entity, 'has_individual', instance) not in graph:\n",
    "                graph.append((entity, 'has_individual', instance))\n",
    "\n",
    "    return graph\n",
    "\n",
    "def generate_knowledge_graph(entity):\n",
    "    \"\"\"Helper function to grab entity-relation from onto and \n",
    "    return as knowledge graph.\n",
    "    \"\"\"\n",
    "    graph = []\n",
    "\n",
    "    # Part 1: Append subclasses\n",
    "    graph = _process_subclasses(entity, graph)\n",
    "\n",
    "    # Part 2: Collect equivalent_to\n",
    "    try:\n",
    "        equivalent_to_list = entity.INDIRECT_equivalent_to  # NOTE: Weird bug here, have to use INDIRECT\n",
    "    except:\n",
    "        equivalent_to_list = []\n",
    "    for et in equivalent_to_list:\n",
    "        # equivalent_to AND objects:\n",
    "        if et.__module__ == 'owlready2.class_construct':\n",
    "            for x in et.Classes:\n",
    "                # For class restriction, retrieve relevant infos inside\n",
    "                if x.__module__ == 'owlready2.class_construct':\n",
    "                    graph = _process_restriction(x, entity, graph)\n",
    "                    \n",
    "    # Part 3: Look into is_a\n",
    "    is_a_list = entity.is_a\n",
    "    for x in is_a_list:\n",
    "        # Entity: is_a indicates subclasses\n",
    "        if x.__module__ == 'owlready2.entity':\n",
    "            graph = _process_entity(x, 'subclass_of', entity, graph)\n",
    "                \n",
    "        # Restriction\n",
    "        elif x.__module__ == 'owlready2.class_construct':\n",
    "            graph = _process_restriction(x, entity, graph)\n",
    "        \n",
    "    # Part 4: Look into instances\n",
    "    graph = _process_instances(entity, graph)\n",
    "    \n",
    "    # Part 5: Some additional filters\n",
    "    graph = _populate_subclass_rel(graph)\n",
    "    \n",
    "    return graph\n",
    "\n",
    "def _filter_graph(graph, onto):\n",
    "    \"\"\"Helper: filter graph from some ill-logical entries.\n",
    "    \"\"\"\n",
    "    filtered_graph = []\n",
    "    # Grab all individuals\n",
    "    individuals = list(onto.individuals())\n",
    "\n",
    "    for edge in graph:\n",
    "        passed = True\n",
    "        # Ill-logical individuals\n",
    "        if edge[0] in individuals:\n",
    "            passed = False\n",
    "        if passed:\n",
    "            filtered_graph.append(edge)\n",
    "    return filtered_graph\n",
    "\n",
    "def keyword_search_onto(keyword, onto):\n",
    "    \"\"\"Search and index key entity from onto given keyword.\n",
    "    \"\"\"\n",
    "    classes = list(onto.classes())\n",
    "    classes_str = [x.name for x in classes]\n",
    "    all_res = difflib.get_close_matches(keyword, classes_str)\n",
    "    # Only grab the most probable search keyword\n",
    "    if len(all_res) > 0:\n",
    "        res = all_res[0]\n",
    "        return classes[classes_str.index(res)]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def _to_string(graph):\n",
    "    \"\"\"Helper: Convert everything collected inside graph list into\n",
    "    string.\n",
    "    \"\"\"\n",
    "    for i in range(len(graph)):\n",
    "        edge = list(graph[i])\n",
    "        for k in range(len(edge)):\n",
    "            if type(edge[k]) is not str:\n",
    "                edge[k] = edge[k].name\n",
    "            edge[k] = edge[k].replace(',', ', ')\n",
    "        graph[i] = (edge[0], edge[1], edge[2])\n",
    "    return graph\n",
    "\n",
    "def ontograf_simple(orig_entity, onto):\n",
    "    \"\"\"Interface func to search and retrieve infor for a given\n",
    "    entity inside onto.\n",
    "    \"\"\"\n",
    "    if orig_entity is None:\n",
    "        return []\n",
    "    \n",
    "    # Initial graph search\n",
    "    graph = generate_knowledge_graph(orig_entity)\n",
    "    \n",
    "    # Prep for other key entities given the initial graph\n",
    "    entities = []\n",
    "    for edge in graph:\n",
    "        entities.append(edge[2])\n",
    "\n",
    "    # 1st-level of filters, append more info from children and parent nodes\n",
    "    for entity in entities:\n",
    "        sub_graph = generate_knowledge_graph(entity)\n",
    "        for edge in sub_graph:\n",
    "            if edge[2] == orig_entity:\n",
    "                if (entity, edge[1], orig_entity) not in graph and entity != orig_entity:\n",
    "                    graph.append((entity, edge[1], orig_entity))\n",
    "\n",
    "    # 2nd-level of filters, filter some ill-logical nodes\n",
    "    graph = _filter_graph(graph, onto)\n",
    "\n",
    "    # Convert everything inside graph into str\n",
    "    graph = _to_string(graph)\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_graphviz(graph, name='KG'):\n",
    "    \"\"\"Helper function to convert edge graph into graphviz.Digraph.\n",
    "    \"\"\"\n",
    "    e = graphviz.Digraph(name)\n",
    "    e.attr('node', shape='box')\n",
    "    for edge in graph:\n",
    "        e.attr('node', shape='box')\n",
    "        e.node(edge[0])\n",
    "        e.node(edge[2])\n",
    "        e.edge(edge[0], edge[2], label=edge[1])\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*20)\n",
    "entity = keyword_search_onto('plasticbottle', onto)\n",
    "print(entity == onto.PlasticBottle, entity)\n",
    "kg = ontograf_simple(entity, onto)\n",
    "print(kg)\n",
    "convert_to_graphviz(kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*20)\n",
    "entity = keyword_search_onto('papercup', onto)\n",
    "print(entity == onto.GlassBottle, entity)\n",
    "kg = ontograf_simple(entity, onto)\n",
    "print(kg)\n",
    "convert_to_graphviz(kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*20)\n",
    "entity = keyword_search_onto('bottle', onto)\n",
    "print(entity == onto.Bottle, entity)\n",
    "kg = ontograf_simple(entity, onto)\n",
    "print(kg)\n",
    "convert_to_graphviz(kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*20)\n",
    "entity = keyword_search_onto('container', onto)\n",
    "print(entity == onto.Container, entity)\n",
    "kg = ontograf_simple(entity, onto)\n",
    "print(kg)\n",
    "convert_to_graphviz(kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*20)\n",
    "entity = keyword_search_onto('plastic', onto)\n",
    "print(entity == onto.Plastic, entity)\n",
    "kg = ontograf_simple(entity, onto)\n",
    "print(kg)\n",
    "convert_to_graphviz(kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*20)\n",
    "entity = keyword_search_onto('glassbottle', onto)\n",
    "print(entity == onto.HumanHand, entity)\n",
    "kg = ontograf_simple(entity, onto)\n",
    "print(kg)\n",
    "convert_to_graphviz(kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*20)\n",
    "entity = keyword_search_onto('cold', onto)\n",
    "print(entity == onto.HumanHand, entity)\n",
    "kg = ontograf_simple(entity, onto)\n",
    "print(kg)\n",
    "convert_to_graphviz(kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*20)\n",
    "entity = keyword_search_onto('hello', onto)\n",
    "print(entity == onto.HumanHand, entity)\n",
    "kg = ontograf_simple(entity, onto)\n",
    "print(kg)\n",
    "convert_to_graphviz(kg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 [Conda DLS]",
   "language": "python",
   "name": "conda-env-Conda_DLS-python3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
